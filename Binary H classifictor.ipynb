{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9185ddbd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-21T11:51:28.555415Z",
     "start_time": "2023-03-21T11:51:22.723859Z"
    }
   },
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.metrics import AUC\n",
    "from tensorflow.keras.regularizers import l2\n",
    "\n",
    "inputs = tf.keras.layers.Input(shape=(272, 480, 3))\n",
    "\n",
    "x = layers.Conv2D(32, (3, 3), activation='relu', padding='same', kernel_initializer='he_normal')(inputs)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.Conv2D(32, (3, 3), activation='relu', padding='same', kernel_initializer='he_normal')(x)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.MaxPooling2D((2, 2))(x)\n",
    "x = layers.Dropout(0.5)(x)\n",
    "\n",
    "x = layers.Conv2D(64, (3, 3), activation='relu', padding='same', kernel_initializer='he_normal')(x)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.Conv2D(64, (3, 3), activation='relu', padding='same', kernel_initializer='he_normal')(x)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.MaxPooling2D((2, 2))(x)\n",
    "x = layers.Dropout(0.5)(x)\n",
    "\n",
    "x = layers.Conv2D(128, (3, 3), activation='relu', padding='same', kernel_initializer='he_normal')(x)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.Conv2D(128, (3, 3), activation='relu', padding='same', kernel_initializer='he_normal')(x)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.MaxPooling2D((2, 2))(x)\n",
    "x = layers.Dropout(0.5)(x)\n",
    "\n",
    "x = layers.Flatten()(x)\n",
    "\n",
    "x = layers.Dense(256, activation='relu', kernel_regularizer=l2(0.001))(x)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.Dropout(0.5)(x)\n",
    "\n",
    "outputs = layers.Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "model = tf.keras.Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics='AUC')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a976728a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-23T11:05:10.880716Z",
     "start_time": "2023-03-23T11:05:08.020300Z"
    }
   },
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.metrics import AUC\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "inputs = tf.keras.layers.Input(shape=(272, 480, 3))\n",
    "\n",
    "x = layers.Conv2D(32, (3, 3), activation='relu', padding='same', kernel_initializer='he_normal')(inputs)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.Conv2D(32, (3, 3), activation='relu', padding='same', kernel_initializer='he_normal')(x)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.MaxPooling2D((2, 2))(x)\n",
    "x = layers.Dropout(0.5)(x)\n",
    "\n",
    "x = layers.Conv2D(64, (3, 3), activation='relu', padding='same', kernel_initializer='he_normal')(x)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.Conv2D(64, (3, 3), activation='relu', padding='same', kernel_initializer='he_normal')(x)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.MaxPooling2D((2, 2))(x)\n",
    "x = layers.Dropout(0.5)(x)\n",
    "\n",
    "x = layers.Conv2D(128, (3, 3), activation='relu', padding='same', kernel_initializer='he_normal')(x)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.Conv2D(128, (3, 3), activation='relu', padding='same', kernel_initializer='he_normal')(x)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.MaxPooling2D((2, 2))(x)\n",
    "x = layers.Dropout(0.5)(x)\n",
    "\n",
    "# Added an additional block with 256 filters\n",
    "x = layers.Conv2D(256, (3, 3), activation='relu', padding='same', kernel_initializer='he_normal')(x)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.Conv2D(256, (3, 3), activation='relu', padding='same', kernel_initializer='he_normal')(x)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.MaxPooling2D((2, 2))(x)\n",
    "x = layers.Dropout(0.5)(x)\n",
    "\n",
    "x = layers.Flatten()(x)\n",
    "\n",
    "x = layers.Dense(512, activation='relu', kernel_regularizer=l2(0.001))(x)  # Increased the number of units\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.Dropout(0.5)(x)\n",
    "\n",
    "outputs = layers.Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "model = tf.keras.Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics='AUC')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a85f63e2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-22T10:23:02.291661Z",
     "start_time": "2023-03-22T10:22:59.657890Z"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "\n",
    "# Define the input shape\n",
    "input_shape = (272, 480, 3)\n",
    "\n",
    "# Define the input tensor\n",
    "inputs = layers.Input(shape=input_shape)\n",
    "\n",
    "# Define the CNN architecture\n",
    "x = layers.Conv2D(32, (3, 3), activation='relu', padding='same', kernel_initializer='he_normal')(inputs)\n",
    "x = layers.MaxPooling2D((2, 2))(x)\n",
    "x = layers.Conv2D(64, (3, 3), activation='relu', padding='same', kernel_initializer='he_normal')(x)\n",
    "x = layers.MaxPooling2D((2, 2))(x)\n",
    "x = layers.Conv2D(128, (3, 3), activation='relu', padding='same', kernel_initializer='he_normal')(x)\n",
    "x = layers.MaxPooling2D((2, 2))(x)\n",
    "x = layers.Flatten()(x)\n",
    "x = layers.Dense(128, activation='relu')(x)\n",
    "outputs = layers.Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "# Create the model\n",
    "model = models.Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics='AUC')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "67808175",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-30T11:01:37.852111Z",
     "start_time": "2023-03-30T11:01:35.117377Z"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "\n",
    "# Define the input shape\n",
    "input_shape = (480, 640, 3)\n",
    "\n",
    "# Define the input tensor\n",
    "inputs = layers.Input(shape=input_shape)\n",
    "\n",
    "# Define the CNN architecture\n",
    "x = layers.Conv2D(32, (3, 3), activation='relu', padding='same')(inputs)\n",
    "x = layers.MaxPooling2D((2, 2))(x)\n",
    "x = layers.Conv2D(64, (3, 3), activation='relu', padding='same')(x)\n",
    "x = layers.MaxPooling2D((2, 2))(x)\n",
    "x = layers.Conv2D(64, (3, 3), activation='relu', padding='same')(x)\n",
    "x = layers.MaxPooling2D((2, 2))(x)\n",
    "x = layers.Flatten()(x)\n",
    "outputs = layers.Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "# Create the model\n",
    "model = models.Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics='AUC')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5536d47d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-30T11:01:41.374709Z",
     "start_time": "2023-03-30T11:01:37.853102Z"
    },
    "code_folding": [
     3
    ]
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "X = np.load('8x640_480.npy')\n",
    "Y = np.load('8y640_480.npy')\n",
    "def swap_zeros_ones(arr):\n",
    "    arr[arr == 0] = 2\n",
    "    arr[arr == 1] = 0\n",
    "    arr[arr == 2] = 1\n",
    "    return arr\n",
    "Y = swap_zeros_ones(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "548e3e83",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-30T11:01:42.279820Z",
     "start_time": "2023-03-30T11:01:41.375706Z"
    }
   },
   "outputs": [],
   "source": [
    "y = []\n",
    "for i in Y:\n",
    "    if np.average(i) == 0:\n",
    "        y.append(0)\n",
    "    else:\n",
    "        y.append(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "231017e5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-30T11:01:42.295757Z",
     "start_time": "2023-03-30T11:01:42.281794Z"
    }
   },
   "outputs": [],
   "source": [
    "y = np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9af47ee1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-30T11:01:46.321298Z",
     "start_time": "2023-03-30T11:01:42.296754Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# Split the data into training and validation sets\n",
    "train_images, val_images, train_labels, val_labels = train_test_split(\n",
    "    X, y, test_size=0.2\n",
    ")\n",
    "\n",
    "# Define the training data generator with data augmentation\n",
    "train_data_gen = ImageDataGenerator(\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True\n",
    ")\n",
    "\n",
    "# Define the validation data generator without data augmentation or rescaling\n",
    "val_data_gen = ImageDataGenerator()\n",
    "\n",
    "# Create the training data iterator\n",
    "train_data_iterator = train_data_gen.flow(\n",
    "    train_images, train_labels,\n",
    "    batch_size=32\n",
    ")\n",
    "\n",
    "# Create the validation data iterator\n",
    "val_data_iterator = val_data_gen.flow(\n",
    "    val_images, val_labels,\n",
    "    batch_size=32\n",
    ")\n",
    "\n",
    "# # Train the model using the training and validation data iterators\n",
    "# model.fit(\n",
    "#     train_data_iterator,\n",
    "#     epochs=epochs,\n",
    "#     steps_per_epoch=len(train_images) // batch_size,\n",
    "#     validation_data=val_data_iterator,\n",
    "#     validation_steps=len(val_images) // batch_size\n",
    "# )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "189fc056",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-30T11:01:46.336258Z",
     "start_time": "2023-03-30T11:01:46.322295Z"
    }
   },
   "outputs": [],
   "source": [
    "from keras.callbacks import EarlyStopping\n",
    "patience = 20\n",
    "early_stopping = EarlyStopping(monitor='val_auc', restore_best_weights = True, min_delta=0.0001, patience= patience, verbose = 1, mode = 'max')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "344b2009",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-30T14:18:20.201742Z",
     "start_time": "2023-03-30T11:01:46.337256Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "104/104 [==============================] - 139s 1s/step - loss: 22.4329 - auc: 0.7213 - val_loss: 0.5166 - val_auc: 0.8539\n",
      "Epoch 2/500\n",
      "104/104 [==============================] - 138s 1s/step - loss: 0.4810 - auc: 0.8527 - val_loss: 0.4313 - val_auc: 0.8880\n",
      "Epoch 3/500\n",
      "104/104 [==============================] - 138s 1s/step - loss: 0.5572 - auc: 0.8350 - val_loss: 0.5263 - val_auc: 0.8149\n",
      "Epoch 4/500\n",
      "104/104 [==============================] - 138s 1s/step - loss: 0.5240 - auc: 0.8162 - val_loss: 0.5277 - val_auc: 0.8698\n",
      "Epoch 5/500\n",
      "104/104 [==============================] - 138s 1s/step - loss: 0.4652 - auc: 0.8643 - val_loss: 0.4807 - val_auc: 0.8531\n",
      "Epoch 6/500\n",
      "104/104 [==============================] - 139s 1s/step - loss: 0.4420 - auc: 0.8719 - val_loss: 0.3854 - val_auc: 0.9031\n",
      "Epoch 7/500\n",
      "104/104 [==============================] - 138s 1s/step - loss: 0.4088 - auc: 0.8907 - val_loss: 0.3254 - val_auc: 0.9277\n",
      "Epoch 8/500\n",
      "104/104 [==============================] - 138s 1s/step - loss: 0.3870 - auc: 0.9055 - val_loss: 0.3284 - val_auc: 0.9323\n",
      "Epoch 9/500\n",
      "104/104 [==============================] - 137s 1s/step - loss: 0.3526 - auc: 0.9224 - val_loss: 0.3110 - val_auc: 0.9386\n",
      "Epoch 10/500\n",
      "104/104 [==============================] - 140s 1s/step - loss: 0.3415 - auc: 0.9285 - val_loss: 0.3006 - val_auc: 0.9425\n",
      "Epoch 11/500\n",
      "104/104 [==============================] - 139s 1s/step - loss: 0.3342 - auc: 0.9313 - val_loss: 0.3027 - val_auc: 0.9387\n",
      "Epoch 12/500\n",
      "104/104 [==============================] - 134s 1s/step - loss: 0.3324 - auc: 0.9304 - val_loss: 0.3359 - val_auc: 0.9370\n",
      "Epoch 13/500\n",
      "104/104 [==============================] - 133s 1s/step - loss: 0.3243 - auc: 0.9349 - val_loss: 0.3020 - val_auc: 0.9471\n",
      "Epoch 14/500\n",
      "104/104 [==============================] - 133s 1s/step - loss: 0.3242 - auc: 0.9367 - val_loss: 0.3170 - val_auc: 0.9405\n",
      "Epoch 15/500\n",
      "104/104 [==============================] - 137s 1s/step - loss: 0.3861 - auc: 0.9120 - val_loss: 0.3239 - val_auc: 0.9371\n",
      "Epoch 16/500\n",
      "104/104 [==============================] - 139s 1s/step - loss: 0.3136 - auc: 0.9396 - val_loss: 0.2915 - val_auc: 0.9474\n",
      "Epoch 17/500\n",
      "104/104 [==============================] - 137s 1s/step - loss: 0.3197 - auc: 0.9345 - val_loss: 0.2877 - val_auc: 0.9507\n",
      "Epoch 18/500\n",
      "104/104 [==============================] - 137s 1s/step - loss: 0.3314 - auc: 0.9326 - val_loss: 0.2943 - val_auc: 0.9475\n",
      "Epoch 19/500\n",
      "104/104 [==============================] - 137s 1s/step - loss: 0.2956 - auc: 0.9466 - val_loss: 0.2757 - val_auc: 0.9526\n",
      "Epoch 20/500\n",
      "104/104 [==============================] - 137s 1s/step - loss: 0.3175 - auc: 0.9382 - val_loss: 0.2934 - val_auc: 0.9455\n",
      "Epoch 21/500\n",
      "104/104 [==============================] - 137s 1s/step - loss: 0.3008 - auc: 0.9427 - val_loss: 0.2497 - val_auc: 0.9596\n",
      "Epoch 22/500\n",
      "104/104 [==============================] - 135s 1s/step - loss: 0.2828 - auc: 0.9486 - val_loss: 0.2637 - val_auc: 0.9560\n",
      "Epoch 23/500\n",
      "104/104 [==============================] - 135s 1s/step - loss: 0.2984 - auc: 0.9447 - val_loss: 0.2830 - val_auc: 0.9477\n",
      "Epoch 24/500\n",
      "104/104 [==============================] - 138s 1s/step - loss: 0.3229 - auc: 0.9332 - val_loss: 0.2806 - val_auc: 0.9510\n",
      "Epoch 25/500\n",
      "104/104 [==============================] - 137s 1s/step - loss: 0.2662 - auc: 0.9556 - val_loss: 0.2527 - val_auc: 0.9614\n",
      "Epoch 26/500\n",
      "104/104 [==============================] - 138s 1s/step - loss: 0.3115 - auc: 0.9402 - val_loss: 0.2411 - val_auc: 0.9614\n",
      "Epoch 27/500\n",
      "104/104 [==============================] - 137s 1s/step - loss: 0.2435 - auc: 0.9611 - val_loss: 0.2381 - val_auc: 0.9631\n",
      "Epoch 28/500\n",
      "104/104 [==============================] - 139s 1s/step - loss: 0.2597 - auc: 0.9581 - val_loss: 0.2816 - val_auc: 0.9634\n",
      "Epoch 29/500\n",
      "104/104 [==============================] - 137s 1s/step - loss: 0.2384 - auc: 0.9653 - val_loss: 0.2285 - val_auc: 0.9669\n",
      "Epoch 30/500\n",
      "104/104 [==============================] - 136s 1s/step - loss: 0.2211 - auc: 0.9686 - val_loss: 0.2153 - val_auc: 0.9685\n",
      "Epoch 31/500\n",
      "104/104 [==============================] - 136s 1s/step - loss: 0.2389 - auc: 0.9650 - val_loss: 0.2349 - val_auc: 0.9637\n",
      "Epoch 32/500\n",
      "104/104 [==============================] - 140s 1s/step - loss: 0.2394 - auc: 0.9646 - val_loss: 0.3339 - val_auc: 0.9704\n",
      "Epoch 33/500\n",
      "104/104 [==============================] - 137s 1s/step - loss: 0.2416 - auc: 0.9629 - val_loss: 0.2236 - val_auc: 0.9672\n",
      "Epoch 34/500\n",
      "104/104 [==============================] - 137s 1s/step - loss: 0.2442 - auc: 0.9626 - val_loss: 0.2484 - val_auc: 0.9698\n",
      "Epoch 35/500\n",
      "104/104 [==============================] - 138s 1s/step - loss: 0.2183 - auc: 0.9688 - val_loss: 0.2118 - val_auc: 0.9725\n",
      "Epoch 36/500\n",
      "104/104 [==============================] - 138s 1s/step - loss: 0.2267 - auc: 0.9681 - val_loss: 0.2066 - val_auc: 0.9734\n",
      "Epoch 37/500\n",
      "104/104 [==============================] - 137s 1s/step - loss: 0.2115 - auc: 0.9707 - val_loss: 0.2159 - val_auc: 0.9707\n",
      "Epoch 38/500\n",
      "104/104 [==============================] - 136s 1s/step - loss: 0.2535 - auc: 0.9587 - val_loss: 0.1907 - val_auc: 0.9768\n",
      "Epoch 39/500\n",
      "104/104 [==============================] - 137s 1s/step - loss: 0.2138 - auc: 0.9710 - val_loss: 0.2080 - val_auc: 0.9741\n",
      "Epoch 40/500\n",
      "104/104 [==============================] - 136s 1s/step - loss: 0.2098 - auc: 0.9694 - val_loss: 0.1955 - val_auc: 0.9711\n",
      "Epoch 41/500\n",
      "104/104 [==============================] - 138s 1s/step - loss: 0.2079 - auc: 0.9695 - val_loss: 0.2626 - val_auc: 0.9684\n",
      "Epoch 42/500\n",
      "104/104 [==============================] - 136s 1s/step - loss: 0.2057 - auc: 0.9720 - val_loss: 0.2943 - val_auc: 0.9699\n",
      "Epoch 43/500\n",
      "104/104 [==============================] - 136s 1s/step - loss: 0.2292 - auc: 0.9664 - val_loss: 0.1951 - val_auc: 0.9720\n",
      "Epoch 44/500\n",
      "104/104 [==============================] - 136s 1s/step - loss: 0.2274 - auc: 0.9659 - val_loss: 0.1766 - val_auc: 0.9771\n",
      "Epoch 45/500\n",
      "104/104 [==============================] - 138s 1s/step - loss: 0.2200 - auc: 0.9696 - val_loss: 0.2166 - val_auc: 0.9729\n",
      "Epoch 46/500\n",
      "104/104 [==============================] - 136s 1s/step - loss: 0.2192 - auc: 0.9685 - val_loss: 0.1771 - val_auc: 0.9791\n",
      "Epoch 47/500\n",
      "104/104 [==============================] - 138s 1s/step - loss: 0.2387 - auc: 0.9622 - val_loss: 0.1866 - val_auc: 0.9818\n",
      "Epoch 48/500\n",
      "104/104 [==============================] - 136s 1s/step - loss: 0.2206 - auc: 0.9691 - val_loss: 0.1769 - val_auc: 0.9776\n",
      "Epoch 49/500\n",
      "104/104 [==============================] - 137s 1s/step - loss: 0.1932 - auc: 0.9748 - val_loss: 0.2145 - val_auc: 0.9762\n",
      "Epoch 50/500\n",
      "104/104 [==============================] - 137s 1s/step - loss: 0.1950 - auc: 0.9741 - val_loss: 0.1724 - val_auc: 0.9815\n",
      "Epoch 51/500\n",
      "104/104 [==============================] - 137s 1s/step - loss: 0.2134 - auc: 0.9720 - val_loss: 0.2115 - val_auc: 0.9699\n",
      "Epoch 52/500\n",
      "104/104 [==============================] - 139s 1s/step - loss: 0.1930 - auc: 0.9755 - val_loss: 0.2337 - val_auc: 0.9732\n",
      "Epoch 53/500\n",
      "104/104 [==============================] - 136s 1s/step - loss: 0.1899 - auc: 0.9759 - val_loss: 0.1832 - val_auc: 0.9777\n",
      "Epoch 54/500\n",
      "104/104 [==============================] - 136s 1s/step - loss: 0.1957 - auc: 0.9758 - val_loss: 0.1826 - val_auc: 0.9825\n",
      "Epoch 55/500\n",
      "104/104 [==============================] - 136s 1s/step - loss: 0.1944 - auc: 0.9753 - val_loss: 0.1847 - val_auc: 0.9848\n",
      "Epoch 56/500\n",
      "104/104 [==============================] - 138s 1s/step - loss: 0.2286 - auc: 0.9657 - val_loss: 0.1771 - val_auc: 0.9795\n",
      "Epoch 57/500\n",
      "104/104 [==============================] - 138s 1s/step - loss: 0.2106 - auc: 0.9712 - val_loss: 0.2094 - val_auc: 0.9733\n",
      "Epoch 58/500\n",
      "104/104 [==============================] - 136s 1s/step - loss: 0.2049 - auc: 0.9730 - val_loss: 0.1914 - val_auc: 0.9746\n",
      "Epoch 59/500\n",
      "104/104 [==============================] - 136s 1s/step - loss: 0.2743 - auc: 0.9540 - val_loss: 0.2066 - val_auc: 0.9730\n",
      "Epoch 60/500\n",
      "104/104 [==============================] - 132s 1s/step - loss: 0.2137 - auc: 0.9708 - val_loss: 0.1755 - val_auc: 0.9853\n",
      "Epoch 61/500\n",
      "104/104 [==============================] - 143s 1s/step - loss: 0.2248 - auc: 0.9669 - val_loss: 0.2063 - val_auc: 0.9747\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 62/500\n",
      "104/104 [==============================] - 139s 1s/step - loss: 0.2241 - auc: 0.9656 - val_loss: 0.1996 - val_auc: 0.9785\n",
      "Epoch 63/500\n",
      "104/104 [==============================] - 139s 1s/step - loss: 0.2223 - auc: 0.9677 - val_loss: 0.2318 - val_auc: 0.9634\n",
      "Epoch 64/500\n",
      "104/104 [==============================] - 137s 1s/step - loss: 0.2732 - auc: 0.9549 - val_loss: 0.2517 - val_auc: 0.9703\n",
      "Epoch 65/500\n",
      "104/104 [==============================] - 137s 1s/step - loss: 0.2313 - auc: 0.9668 - val_loss: 0.1887 - val_auc: 0.9801\n",
      "Epoch 66/500\n",
      "104/104 [==============================] - 139s 1s/step - loss: 0.2264 - auc: 0.9665 - val_loss: 0.1688 - val_auc: 0.9856\n",
      "Epoch 67/500\n",
      "104/104 [==============================] - 137s 1s/step - loss: 0.2527 - auc: 0.9620 - val_loss: 0.2561 - val_auc: 0.9642\n",
      "Epoch 68/500\n",
      "104/104 [==============================] - 137s 1s/step - loss: 0.2587 - auc: 0.9597 - val_loss: 0.2439 - val_auc: 0.9749\n",
      "Epoch 69/500\n",
      "104/104 [==============================] - 137s 1s/step - loss: 0.2112 - auc: 0.9703 - val_loss: 0.1866 - val_auc: 0.9822\n",
      "Epoch 70/500\n",
      "104/104 [==============================] - 136s 1s/step - loss: 0.2264 - auc: 0.9663 - val_loss: 0.1978 - val_auc: 0.9740\n",
      "Epoch 71/500\n",
      "104/104 [==============================] - 137s 1s/step - loss: 0.2104 - auc: 0.9719 - val_loss: 0.2186 - val_auc: 0.9734\n",
      "Epoch 72/500\n",
      "104/104 [==============================] - 137s 1s/step - loss: 0.2017 - auc: 0.9729 - val_loss: 0.2507 - val_auc: 0.9706\n",
      "Epoch 73/500\n",
      "104/104 [==============================] - 136s 1s/step - loss: 0.2448 - auc: 0.9638 - val_loss: 0.2086 - val_auc: 0.9723\n",
      "Epoch 74/500\n",
      "104/104 [==============================] - 136s 1s/step - loss: 0.1805 - auc: 0.9792 - val_loss: 0.2068 - val_auc: 0.9801\n",
      "Epoch 75/500\n",
      "104/104 [==============================] - 137s 1s/step - loss: 0.1853 - auc: 0.9781 - val_loss: 0.2147 - val_auc: 0.9809\n",
      "Epoch 76/500\n",
      "104/104 [==============================] - 138s 1s/step - loss: 0.1986 - auc: 0.9742 - val_loss: 0.1675 - val_auc: 0.9845\n",
      "Epoch 77/500\n",
      "104/104 [==============================] - 136s 1s/step - loss: 0.2000 - auc: 0.9742 - val_loss: 0.1996 - val_auc: 0.9755\n",
      "Epoch 78/500\n",
      "104/104 [==============================] - 136s 1s/step - loss: 0.2141 - auc: 0.9697 - val_loss: 0.2603 - val_auc: 0.9648\n",
      "Epoch 79/500\n",
      "104/104 [==============================] - 137s 1s/step - loss: 0.2882 - auc: 0.9499 - val_loss: 0.3504 - val_auc: 0.9226\n",
      "Epoch 80/500\n",
      "104/104 [==============================] - 135s 1s/step - loss: 0.3083 - auc: 0.9420 - val_loss: 0.2250 - val_auc: 0.9669\n",
      "Epoch 81/500\n",
      "104/104 [==============================] - 136s 1s/step - loss: 0.3186 - auc: 0.9376 - val_loss: 0.2243 - val_auc: 0.9727\n",
      "Epoch 82/500\n",
      "104/104 [==============================] - 138s 1s/step - loss: 0.2237 - auc: 0.9679 - val_loss: 0.2039 - val_auc: 0.9727\n",
      "Epoch 83/500\n",
      "104/104 [==============================] - 140s 1s/step - loss: 0.2136 - auc: 0.9700 - val_loss: 0.1937 - val_auc: 0.9783\n",
      "Epoch 84/500\n",
      "104/104 [==============================] - 137s 1s/step - loss: 0.2017 - auc: 0.9726 - val_loss: 0.2194 - val_auc: 0.9758\n",
      "Epoch 85/500\n",
      "104/104 [==============================] - 137s 1s/step - loss: 0.1868 - auc: 0.9764 - val_loss: 0.2275 - val_auc: 0.9683\n",
      "Epoch 86/500\n",
      "104/104 [==============================] - ETA: 0s - loss: 0.2012 - auc: 0.9726Restoring model weights from the end of the best epoch: 66.\n",
      "104/104 [==============================] - 136s 1s/step - loss: 0.2012 - auc: 0.9726 - val_loss: 0.1744 - val_auc: 0.9805\n",
      "Epoch 86: early stopping\n"
     ]
    }
   ],
   "source": [
    "# Train the model using the training and validation data iterators\n",
    "history = model.fit(\n",
    "    train_data_iterator,\n",
    "    epochs=500,\n",
    "    batch_size=32,\n",
    "    validation_data=val_data_iterator,\n",
    "    callbacks=[early_stopping]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6092330c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-30T10:59:37.680884Z",
     "start_time": "2023-03-30T10:50:45.957312Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "104/104 [==============================] - 14s 125ms/step - loss: 21.3676 - auc: 0.7077 - val_loss: 0.8385 - val_auc: 0.5792\n",
      "Epoch 2/500\n",
      "104/104 [==============================] - 41s 400ms/step - loss: 0.4212 - auc: 0.8905 - val_loss: 0.4887 - val_auc: 0.7177\n",
      "Epoch 3/500\n",
      "104/104 [==============================] - 59s 571ms/step - loss: 0.2666 - auc: 0.9577 - val_loss: 0.6834 - val_auc: 0.7271\n",
      "Epoch 4/500\n",
      "104/104 [==============================] - 59s 570ms/step - loss: 0.1770 - auc: 0.9797 - val_loss: 0.5913 - val_auc: 0.7881\n",
      "Epoch 5/500\n",
      "104/104 [==============================] - 59s 571ms/step - loss: 0.1094 - auc: 0.9914 - val_loss: 0.8278 - val_auc: 0.7108\n",
      "Epoch 6/500\n",
      "104/104 [==============================] - 59s 570ms/step - loss: 0.1017 - auc: 0.9917 - val_loss: 0.6918 - val_auc: 0.7593\n",
      "Epoch 7/500\n",
      "104/104 [==============================] - 59s 571ms/step - loss: 0.0617 - auc: 0.9958 - val_loss: 1.0073 - val_auc: 0.7747\n",
      "Epoch 8/500\n",
      "104/104 [==============================] - 60s 573ms/step - loss: 0.0661 - auc: 0.9953 - val_loss: 0.9147 - val_auc: 0.7636\n",
      "Epoch 9/500\n",
      "104/104 [==============================] - 61s 585ms/step - loss: 0.0421 - auc: 0.9981 - val_loss: 0.9974 - val_auc: 0.7451\n",
      "Epoch 10/500\n",
      " 95/104 [==========================>...] - ETA: 5s - loss: 0.1144 - auc: 0.9900"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m500\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_split\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0.2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m32\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mearly_stopping\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\training.py:1570\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1568\u001b[0m logs \u001b[38;5;241m=\u001b[39m tmp_logs\n\u001b[0;32m   1569\u001b[0m end_step \u001b[38;5;241m=\u001b[39m step \u001b[38;5;241m+\u001b[39m data_handler\u001b[38;5;241m.\u001b[39mstep_increment\n\u001b[1;32m-> 1570\u001b[0m \u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mon_train_batch_end\u001b[49m\u001b[43m(\u001b[49m\u001b[43mend_step\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1571\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstop_training:\n\u001b[0;32m   1572\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\callbacks.py:470\u001b[0m, in \u001b[0;36mCallbackList.on_train_batch_end\u001b[1;34m(self, batch, logs)\u001b[0m\n\u001b[0;32m    463\u001b[0m \u001b[38;5;124;03m\"\"\"Calls the `on_train_batch_end` methods of its callbacks.\u001b[39;00m\n\u001b[0;32m    464\u001b[0m \n\u001b[0;32m    465\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[0;32m    466\u001b[0m \u001b[38;5;124;03m    batch: Integer, index of batch within the current epoch.\u001b[39;00m\n\u001b[0;32m    467\u001b[0m \u001b[38;5;124;03m    logs: Dict. Aggregated metric results up until this batch.\u001b[39;00m\n\u001b[0;32m    468\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    469\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_should_call_train_batch_hooks:\n\u001b[1;32m--> 470\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_batch_hook\u001b[49m\u001b[43m(\u001b[49m\u001b[43mModeKeys\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTRAIN\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mend\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlogs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\callbacks.py:317\u001b[0m, in \u001b[0;36mCallbackList._call_batch_hook\u001b[1;34m(self, mode, hook, batch, logs)\u001b[0m\n\u001b[0;32m    315\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_batch_begin_hook(mode, batch, logs)\n\u001b[0;32m    316\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m hook \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mend\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m--> 317\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_batch_end_hook\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    318\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    319\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    320\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnrecognized hook: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mhook\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    321\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mExpected values are [\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbegin\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mend\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    322\u001b[0m     )\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\callbacks.py:340\u001b[0m, in \u001b[0;36mCallbackList._call_batch_end_hook\u001b[1;34m(self, mode, batch, logs)\u001b[0m\n\u001b[0;32m    337\u001b[0m     batch_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_batch_start_time\n\u001b[0;32m    338\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_batch_times\u001b[38;5;241m.\u001b[39mappend(batch_time)\n\u001b[1;32m--> 340\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_batch_hook_helper\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhook_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    342\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_batch_times) \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_batches_for_timing_check:\n\u001b[0;32m    343\u001b[0m     end_hook_name \u001b[38;5;241m=\u001b[39m hook_name\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\callbacks.py:388\u001b[0m, in \u001b[0;36mCallbackList._call_batch_hook_helper\u001b[1;34m(self, hook_name, batch, logs)\u001b[0m\n\u001b[0;32m    386\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m callback \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallbacks:\n\u001b[0;32m    387\u001b[0m     hook \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(callback, hook_name)\n\u001b[1;32m--> 388\u001b[0m     \u001b[43mhook\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    390\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_timing:\n\u001b[0;32m    391\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m hook_name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_hook_times:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\callbacks.py:1081\u001b[0m, in \u001b[0;36mProgbarLogger.on_train_batch_end\u001b[1;34m(self, batch, logs)\u001b[0m\n\u001b[0;32m   1080\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mon_train_batch_end\u001b[39m(\u001b[38;5;28mself\u001b[39m, batch, logs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m-> 1081\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_batch_update_progbar\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\callbacks.py:1157\u001b[0m, in \u001b[0;36mProgbarLogger._batch_update_progbar\u001b[1;34m(self, batch, logs)\u001b[0m\n\u001b[0;32m   1153\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mseen \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m add_seen\n\u001b[0;32m   1155\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   1156\u001b[0m     \u001b[38;5;66;03m# Only block async when verbose = 1.\u001b[39;00m\n\u001b[1;32m-> 1157\u001b[0m     logs \u001b[38;5;241m=\u001b[39m \u001b[43mtf_utils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msync_to_numpy_or_python_type\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlogs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1158\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprogbar\u001b[38;5;241m.\u001b[39mupdate(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mseen, \u001b[38;5;28mlist\u001b[39m(logs\u001b[38;5;241m.\u001b[39mitems()), finalize\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\utils\\tf_utils.py:635\u001b[0m, in \u001b[0;36msync_to_numpy_or_python_type\u001b[1;34m(tensors)\u001b[0m\n\u001b[0;32m    632\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m t\n\u001b[0;32m    633\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m t\u001b[38;5;241m.\u001b[39mitem() \u001b[38;5;28;01mif\u001b[39;00m np\u001b[38;5;241m.\u001b[39mndim(t) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m t\n\u001b[1;32m--> 635\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap_structure\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_to_single_numpy_or_python_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\util\\nest.py:917\u001b[0m, in \u001b[0;36mmap_structure\u001b[1;34m(func, *structure, **kwargs)\u001b[0m\n\u001b[0;32m    913\u001b[0m flat_structure \u001b[38;5;241m=\u001b[39m (flatten(s, expand_composites) \u001b[38;5;28;01mfor\u001b[39;00m s \u001b[38;5;129;01min\u001b[39;00m structure)\n\u001b[0;32m    914\u001b[0m entries \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mflat_structure)\n\u001b[0;32m    916\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m pack_sequence_as(\n\u001b[1;32m--> 917\u001b[0m     structure[\u001b[38;5;241m0\u001b[39m], [func(\u001b[38;5;241m*\u001b[39mx) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m entries],\n\u001b[0;32m    918\u001b[0m     expand_composites\u001b[38;5;241m=\u001b[39mexpand_composites)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\util\\nest.py:917\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    913\u001b[0m flat_structure \u001b[38;5;241m=\u001b[39m (flatten(s, expand_composites) \u001b[38;5;28;01mfor\u001b[39;00m s \u001b[38;5;129;01min\u001b[39;00m structure)\n\u001b[0;32m    914\u001b[0m entries \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mflat_structure)\n\u001b[0;32m    916\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m pack_sequence_as(\n\u001b[1;32m--> 917\u001b[0m     structure[\u001b[38;5;241m0\u001b[39m], [\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m entries],\n\u001b[0;32m    918\u001b[0m     expand_composites\u001b[38;5;241m=\u001b[39mexpand_composites)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\utils\\tf_utils.py:628\u001b[0m, in \u001b[0;36msync_to_numpy_or_python_type.<locals>._to_single_numpy_or_python_type\u001b[1;34m(t)\u001b[0m\n\u001b[0;32m    625\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_to_single_numpy_or_python_type\u001b[39m(t):\n\u001b[0;32m    626\u001b[0m     \u001b[38;5;66;03m# Don't turn ragged or sparse tensors to NumPy.\u001b[39;00m\n\u001b[0;32m    627\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(t, tf\u001b[38;5;241m.\u001b[39mTensor):\n\u001b[1;32m--> 628\u001b[0m         t \u001b[38;5;241m=\u001b[39m \u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnumpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    629\u001b[0m     \u001b[38;5;66;03m# Strings, ragged and sparse tensors don't have .item(). Return them\u001b[39;00m\n\u001b[0;32m    630\u001b[0m     \u001b[38;5;66;03m# as-is.\u001b[39;00m\n\u001b[0;32m    631\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(t, (np\u001b[38;5;241m.\u001b[39mndarray, np\u001b[38;5;241m.\u001b[39mgeneric)):\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py:1157\u001b[0m, in \u001b[0;36m_EagerTensorBase.numpy\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1134\u001b[0m \u001b[38;5;124;03m\"\"\"Copy of the contents of this Tensor into a NumPy array or scalar.\u001b[39;00m\n\u001b[0;32m   1135\u001b[0m \n\u001b[0;32m   1136\u001b[0m \u001b[38;5;124;03mUnlike NumPy arrays, Tensors are immutable, so this method has to copy\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1154\u001b[0m \u001b[38;5;124;03m    NumPy dtype.\u001b[39;00m\n\u001b[0;32m   1155\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1156\u001b[0m \u001b[38;5;66;03m# TODO(slebedev): Consider avoiding a copy for non-CPU or remote tensors.\u001b[39;00m\n\u001b[1;32m-> 1157\u001b[0m maybe_arr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_numpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m   1158\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m maybe_arr\u001b[38;5;241m.\u001b[39mcopy() \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(maybe_arr, np\u001b[38;5;241m.\u001b[39mndarray) \u001b[38;5;28;01melse\u001b[39;00m maybe_arr\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py:1123\u001b[0m, in \u001b[0;36m_EagerTensorBase._numpy\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1121\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_numpy\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m   1122\u001b[0m   \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1123\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_numpy_internal\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1124\u001b[0m   \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m   1125\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_status_to_exception(e) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "history = model.fit(X, y, epochs = 500, validation_split = 0.2, batch_size = 32, callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "47b794e8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-30T14:19:23.825261Z",
     "start_time": "2023-03-30T14:19:23.787363Z"
    }
   },
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "dim1 = 480\n",
    "dim2 = 640\n",
    "X = np.array(Image.open('Video to frames/Пустое/120034_X.jpg').resize((dim2,dim1))).reshape(1,dim1,dim2,3).astype(np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cd44e82a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-30T14:19:24.154689Z",
     "start_time": "2023-03-30T14:19:24.138732Z"
    }
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (2333796975.py, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[13], line 2\u001b[1;36m\u001b[0m\n\u001b[1;33m    X =\u001b[0m\n\u001b[1;37m        ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "X = \n",
    "plt.imshow(X.reshape((dim1,dim2,3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cb72ee9d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-30T14:19:25.093748Z",
     "start_time": "2023-03-30T14:19:24.987486Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 53ms/step\n"
     ]
    }
   ],
   "source": [
    "a = model.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1a0e1932",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-30T14:19:26.280832Z",
     "start_time": "2023-03-30T14:19:26.274848Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.09414208]], dtype=float32)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "99c02f40",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-30T14:19:39.107613Z",
     "start_time": "2023-03-30T14:19:38.315068Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 3 of 3). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: binary_classificator_H_v5_640x480\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: binary_classificator_H_v5_640x480\\assets\n"
     ]
    }
   ],
   "source": [
    "model.save('binary_classificator_H_v5_640x480')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "baa3495c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-29T10:41:31.608732Z",
     "start_time": "2023-03-29T10:41:31.035266Z"
    }
   },
   "outputs": [],
   "source": [
    "Y = np.load('7x2handsonly.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "40f4b905",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-29T10:41:32.922354Z",
     "start_time": "2023-03-29T10:41:31.609729Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "66/66 [==============================] - 1s 13ms/step\n"
     ]
    }
   ],
   "source": [
    "Y_pred = model.predict(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4913001e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-29T10:41:32.938312Z",
     "start_time": "2023-03-29T10:41:32.923353Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9690924"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.average(Y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7deecbb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
